# Copyright 2015 The Chromium Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

"""Task queue endpoints for creating and updating issues on issue tracker."""

import datetime
import json
import logging
import random
import sha
import webapp2

from google.appengine.api import taskqueue
from google.appengine.api import urlfetch
from google.appengine.ext import ndb

from issue_tracker.issue_tracker_api import IssueTrackerAPI
from issue_tracker.issue import Issue


FLAKY_RUNS_TEMPLATE = (
    'Detected new flakes for test/step "%(name)s":\n\n%(flaky_runs)s\n\n'
    'This message was automatically generated by the chromium-try-flakes app.')
FLAKY_RUN_TEMPLATE = (
    '  Failure: %(failure_url)s.\n  Success: %(success_url)s.\n')
SUMMARY_TEMPLATE = 'Test/step "%(name)s" is flaky'
DESCRIPTION_TEMPLATE = (
    '%(summary)s.\n\n'
    'This issue was created automatically by the chromium-try-flakes app and '
    'was assigned to the current sheriff. Please find the right owner to fix '
    'the respective test/step and re-assign this issue to them. If the '
    'step/test is infrastructure-related, please add a label Infra=Troopers, '
    'remove yourself as an owner and mark the issue as Untriaged.')
REOPENED_DESCRIPTION_TEMPLATE = (
    '%(description)s\n\n'
    'This flaky test/step was previously tracked in issue %(old_issue)d.')
ROTATIONS_URL = 'http://chromium-build.appspot.com/p/chromium/all_rotations.js'
GOOGLER_MAPPING_URL = 'https://chromium-access.appspot.com/auto/mapping'


class UpdateIssue(webapp2.RequestHandler):
  @ndb.non_transactional
  def _get_flaky_runs(self, flake):
    # Only report up to 20 last runs.
    num_runs = min(len(flake.occurrences) - flake.num_reported_flaky_runs, 20)
    return ndb.get_multi(flake.occurrences[-num_runs:])

  @ndb.non_transactional
  def _format_flaky_runs_msg(self, test_name, new_flaky_runs):
    flaky_run_msg_parts = []
    for run in new_flaky_runs:
      flaky_run_msg_parts.append(
          FLAKY_RUN_TEMPLATE % {'failure_url': run.failure_run.get().getURL(),
                                'success_url': run.success_run.get().getURL()})
    return FLAKY_RUNS_TEMPLATE % {'flaky_runs': '\n'.join(flaky_run_msg_parts),
                                  'name': test_name}

  def recreate_issue_for_flake(self, flake):
    """Updates a flake to re-create an issue and creates a respective task."""
    flake.old_issue_id = flake.issue_id
    flake.issue_id = 0
    flake.put()
    taskqueue.add(url='/issues/process/%s' % flake.key.urlsafe(),
                  queue_name='issue-updates', transactional=True)

  @ndb.transactional
  def post(self, urlsafe_key):
    """Updates an issue on the issue tracker."""
    now = datetime.datetime.utcnow()
    flake = ndb.Key(urlsafe=urlsafe_key).get()

    # Update issues at most once a day.
    if flake.issue_last_updated > now - datetime.timedelta(days=1):
      return

    # Only update issues if there are new flaky runs.
    if flake.num_reported_flaky_runs == len(flake.occurrences):
      return

    # Retrieve flaky runs outside of the transaction, because we are not
    # planning to modify them and because there could be more of them than the
    # number of groups supported by cross-group transactions on AppEngine.
    new_flaky_runs = self._get_flaky_runs(flake)
    flake.num_reported_flaky_runs = len(flake.occurrences)

    api = IssueTrackerAPI('chromium')
    issue = api.getIssue(flake.issue_id)

    # Handle cases when an issue has been closed. We need to do this in a loop
    # because we might move onto another issue.
    seen_issues = set()
    while not issue.open:
      if issue.status == 'Duplicate':
        # If the issue was marked as duplicate, we update the issue ID stored in
        # datastore to the one it was merged into and continue working with the
        # new issue.
        seen_issues.add(issue.id)
        if issue.merged_into not in seen_issues:
          flake.issue_id = issue.merged_into
          issue = api.getIssue(flake.issue_id)
        else:
          logging.info('Detected issue duplication loop: %s. Re-creating an '
                       'issue for the flake %s.', seen_issues, flake.name)
          self.recreate_issue_for_flake(flake)
          return
      else:  # Fixed, WontFix, Verified, Archived, custom status
        # If the issue was closed, we do not update it. This allows changes made
        # to reduce flakiness to propagate and take effect. If after one week we
        # still see flakiness, we will create a new issue.
        now = datetime.datetime.utcnow()
        if issue.updated < now - datetime.timedelta(weeks=1):
          self.recreate_issue_for_flake(flake)
        return

    new_flaky_runs_msg = self._format_flaky_runs_msg(flake.name, new_flaky_runs)
    api.update(issue, comment=new_flaky_runs_msg)
    logging.info('Updated issue %d for flake %s with %d flake runs',
                 flake.issue_id, flake.name, len(new_flaky_runs))
    flake.issue_last_updated = now

    # Note that if transaction fails for some reason at this point, we may post
    # updates multiple times. On the other hand, this should be extremely rare
    # becase we set the number of concurrently running tasks to 1, therefore
    # there should be no contention for updating this issue's entity.
    flake.put()


class CreateIssue(webapp2.RequestHandler):
  def _get_googler_mapping(self):
    # Get and parse Googler mapping.
    content = urlfetch.fetch(GOOGLER_MAPPING_URL,
                             follow_redirects=False).content
    lines = [line.split(',') for line in content.splitlines()]
    return {google_email: chromium_email
            for chromium_email, google_email in lines}

  def _get_current_sheriff_emails(self):
    # Get all rotations as JSON.
    urlfetch.set_default_fetch_deadline(60)
    rotations = json.loads(urlfetch.fetch(ROTATIONS_URL).content)

    # Find Chrome rotation for today.
    today = datetime.datetime.utcnow().strftime('%Y-%m-%d')
    for day in rotations['calendar']:
      if day['date'] == today:
        chrome_rotation_index = rotations['rotations'].index('chrome')
        sheriffs = day['participants'][chrome_rotation_index]
        break

    # Get Googler mapping and map all emails to @chromium.org.
    googler_mapping = self._get_googler_mapping()
    emails = []
    for sheriff in sheriffs:
      if '@' not in sheriff:
        sheriff = '%s@google.com' % sheriff
      emails.append(googler_mapping.get(sheriff, sheriff))
    return emails

  @ndb.transactional
  def post(self, urlsafe_key):
    flake = ndb.Key(urlsafe=urlsafe_key).get()

    summary = SUMMARY_TEMPLATE % {'name': flake.name}
    description = DESCRIPTION_TEMPLATE % {'summary': summary}
    if flake.old_issue_id:
      description = REOPENED_DESCRIPTION_TEMPLATE % {
          'description': description, 'old_issue': flake.old_issue_id}

    api = IssueTrackerAPI('chromium')
    sheriff_emails = self._get_current_sheriff_emails()
    issue = Issue({'summary': summary,
                   'description': description,
                   'status': 'Assigned',
                   'owner': {'name': random.choice(sheriff_emails)},
                   'cc': [{'name': email} for email in sheriff_emails],
                   'labels': ['Type-Bug', 'Pri-1', 'Cr-Tests-Flaky',
                              'Via-TryFlakes', 'Sheriff-Chromium']})
    flake.issue_id = api.create(issue).id

    logging.info('Created a new issue %d for flake %s', flake.issue_id,
                 flake.name)
    flake.put()

    # Update the newly created issue with the latest flaky runs.
    taskqueue.add(url='/issues/update/%s' % flake.key.urlsafe(),
                  queue_name='issue-updates', transactional=True)


class ProcessIssue(webapp2.RequestHandler):
  @ndb.transactional
  def post(self, urlsafe_key):
    flake = ndb.Key(urlsafe=urlsafe_key).get()

    if flake.issue_id > 0:
      taskqueue.add(url='/issues/update/%s' % flake.key.urlsafe(),
                    queue_name='issue-updates', transactional=True)
    else:
      # We reduce the likely hood of creating multiple issues for the same flake
      # by using named tasks. If two processes schedule two tasks with the same
      # name, only one will be executed. We also append previous issue ID to the
      # name to allow re-creating issues, e.g. when a previous issue was clsoed.
      task_id = sha.new(flake.name).hexdigest()  # sanitize name for task
      task_name = 'create_issue_%s_%s' % (task_id, flake.old_issue_id)
      try:
        taskqueue.add(name=task_name, queue_name='issue-updates',
                      url='/issues/create/%s' % flake.key.urlsafe())
      except taskqueue.TombstonedTaskError:
        pass
