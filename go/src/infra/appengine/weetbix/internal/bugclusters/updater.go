// Copyright 2021 The Chromium Authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

package bugclusters

import (
	"context"
	"fmt"
	"regexp"

	"infra/appengine/weetbix/internal/clustering"
	mpb "infra/monorailv2/api/v3/api_proto"

	"go.chromium.org/luci/common/errors"
	"go.chromium.org/luci/server/span"
)

// TODO (crbug.com/1243174): Currently analysis is hardcoded to only analyse
// one LUCI project, which is recorded here.
const analysisProject = "chromium"

// monorailPageSize is the maximum number of issues that can be requested
// through GetIssues at a time. This limit is set by monorail.
const monorailPageSize = 100

// bugRe matches Weetbix bug names, like
// "monorail/{monorail_project}/{numeric_id}".
var bugRe = regexp.MustCompile(`^monorail/([a-z0-9\-_]+)/([0-9]+)$`)

// monorailRe matches monorail issue names, like
// "monorail/{monorail_project}/{numeric_id}".
var monorailRe = regexp.MustCompile(`^projects/([a-z0-9\-_]+)/issues/([0-9]+)$`)

// MonorailClient is an interface for accessing monorail.
type MonorailClient interface {
	// MakeIssue creates a new issue in monorail.
	MakeIssue(ctx context.Context, req *mpb.MakeIssueRequest) (*mpb.Issue, error)
	// GetIssues retrieves the specified issues from monorail. The same issue
	// may be requested multiple times, and it is guaranteed the i_th issue
	// returned matches the i_th issue requested. Maximum of 100 issues
	// requested at a time.
	GetIssues(ctx context.Context, names []string) ([]*mpb.Issue, error)
}

// ClusterClient is an interface for accessing cluster analysis.
type ClusterClient interface {
	// ReadImpactfulClusters reads analysis for clusters matching the
	// specified criteria.
	ReadImpactfulClusters(ctx context.Context, opts clustering.ImpactfulClusterReadOptions) ([]*clustering.Cluster, error)
}

// IssueGenerator represents a process for generating issues from clusters.
type IssueGenerator interface {
	// PrepareNew prepares a new bug from the given cluster.
	PrepareNew(cluster *clustering.Cluster) *mpb.MakeIssueRequest
}

// BugUpdater performs updates to Monorail bugs and BugClusters to keep them
// in sync with clusters generated by analysis.
type BugUpdater struct {
	monorailClient MonorailClient
	clusterClient  ClusterClient
	issueGenerator IssueGenerator
	// thresholds are the impact thresholds at which bugs should be filed.
	thresholds clustering.ImpactThresholds
	// MaxBugsFiledPerRun is the maximum number of bugs to file each time
	// BugUpdater runs. This throttles the rate of changes to monorail.
	MaxBugsFiledPerRun int
}

// NewBugUpdater initialises a new BugUpdater. The specified impact thresholds are used
// when determining whether to a file a bug.
func NewBugUpdater(mc MonorailClient, cc ClusterClient, ig IssueGenerator, thresholds clustering.ImpactThresholds) *BugUpdater {
	return &BugUpdater{
		monorailClient:     mc,
		clusterClient:      cc,
		issueGenerator:     ig,
		thresholds:         thresholds,
		MaxBugsFiledPerRun: 1, // Default value.
	}
}

// Run updates bug clusters to match high-impact clusters as identified by analysis.
func (b *BugUpdater) Run(ctx context.Context) error {
	bcByAssociatedCluster, err := b.readActiveBugClusters(ctx)
	if err != nil {
		return errors.Annotate(err, "read active bug clusters").Err()
	}
	var clusterIDs []string
	for _, bcd := range bcByAssociatedCluster {
		clusterIDs = append(clusterIDs, bcd.bc.AssociatedClusterID)
	}
	clusters, err := b.clusterClient.ReadImpactfulClusters(ctx, clustering.ImpactfulClusterReadOptions{
		Project:                 analysisProject,
		Thresholds:              b.thresholds,
		AlwaysIncludeClusterIDs: clusterIDs,
	})
	if err != nil {
		return errors.Annotate(err, "read impactful clusters").Err()
	}

	var toCreateBugsFor []*clustering.Cluster
	for _, cluster := range clusters {
		key := clusterKey(cluster.Project, cluster.ClusterID)

		// Find new bugs to create.
		_, ok := bcByAssociatedCluster[key]
		if !ok {
			toCreateBugsFor = append(toCreateBugsFor, cluster)
		}

		// TODO(crbug/1243174): Update existing bugs, by looking at
		// BugClusterDetails for existing bug clusters and determining
		// if priority is still consistent with current impact.
	}

	bugsFiled := 0
	for _, cluster := range toCreateBugsFor {
		if err := b.createBugCluster(ctx, cluster); err != nil {
			return err
		}
		// Throttle how many bugs may be filed each time.
		bugsFiled++
		if bugsFiled >= b.MaxBugsFiledPerRun {
			break
		}
	}

	return err
}

// BugClusterDetails groups together all available information about a
// bug cluster. This includes the bug cluster definition itself, as well
// as the monorail issue that was filed.
type BugClusterDetails struct {
	bc    *BugCluster
	issue *mpb.Issue
}

// createBugCluster files a new bug for the given analysis cluster,
// and stores the association from analysis cluster to bug in the bug
// clusters table.
func (b *BugUpdater) createBugCluster(ctx context.Context, cluster *clustering.Cluster) error {
	req := b.issueGenerator.PrepareNew(cluster)
	// Save the issue in Monorail.
	issue, err := b.monorailClient.MakeIssue(ctx, req)
	if err != nil {
		return errors.Annotate(err, "create issue in monorail").Err()
	}

	bug, err := fromMonorailIssueName(issue.Name)
	if err != nil {
		return errors.Annotate(err, "parsing monorail issue name").Err()
	}

	// Create a bug cluster entry linking the cluster with the bug.
	bc := &BugCluster{
		Project:             cluster.Project,
		Bug:                 bug,
		AssociatedClusterID: cluster.ClusterID,
		IsActive:            true,
	}
	create := func(ctx context.Context) error {
		return Create(ctx, bc)
	}
	if _, err := span.ReadWriteTransaction(ctx, create); err != nil {
		return errors.Annotate(err, "create bug cluster").Err()
	}
	return nil
}

func (b *BugUpdater) readActiveBugClusters(ctx context.Context) (map[string]*BugClusterDetails, error) {
	bcs, err := ReadActive(span.Single(ctx))
	if err != nil {
		return nil, err
	}

	// Calculate the number of requests required, rounding up
	// to the nearest page.
	pages := (len(bcs) + (monorailPageSize - 1)) / monorailPageSize

	bcByAssociatedCluster := make(map[string]*BugClusterDetails)
	for i := 0; i < pages; i++ {
		// Divide bug clusters into pages of monorailPageSize.
		pageEnd := i*monorailPageSize + (monorailPageSize - 1)
		if pageEnd > len(bcs) {
			pageEnd = len(bcs)
		}
		bcPage := bcs[i*monorailPageSize : pageEnd]

		var names []string
		for _, bc := range bcPage {
			name, err := toMonorailIssueName(bc.Bug)
			if err != nil {
				return nil, err
			}
			names = append(names, name)
		}
		// Guarantees result array in 1:1 correspondence to requested names.
		issues, err := b.monorailClient.GetIssues(ctx, names)
		if err != nil {
			return nil, err
		}
		for i, bc := range bcPage {
			key := clusterKey(bc.Project, bc.AssociatedClusterID)
			bcByAssociatedCluster[key] = &BugClusterDetails{
				bc:    bc,
				issue: issues[i],
			}
		}
	}
	return bcByAssociatedCluster, nil
}

// clusterKey returns the key used for clusters in dictionaries. The cluster
// ID is namespaced within the LUCI project for which Weetbix is performing
// analysis.
func clusterKey(project string, clusterID string) string {
	return fmt.Sprintf("%q/%q", project, clusterID)
}

// toMonorailIssueName converts a Weetbix bug name like
// "monorail/{monorail_project}/{numeric_id}" to a monorail issue name like
// "projects/{project}/issues/{numeric_id}".
func toMonorailIssueName(bug string) (string, error) {
	parts := bugRe.FindStringSubmatch(bug)
	if parts == nil {
		return "", fmt.Errorf("invalid bug %q", bug)
	}
	return fmt.Sprintf("projects/%s/issues/%s", parts[1], parts[2]), nil
}

// fromMonorailIssueName converts a monorail issue name like
// "projects/{project}/issues/{numeric_id}" to a Weetbix bug name like
// "monorail/{monorail_project}/{numeric_id}".
func fromMonorailIssueName(name string) (string, error) {
	parts := monorailRe.FindStringSubmatch(name)
	if parts == nil {
		return "", fmt.Errorf("invalid monorail issue name %q", name)
	}
	return fmt.Sprintf("monorail/%s/%s", parts[1], parts[2]), nil
}
